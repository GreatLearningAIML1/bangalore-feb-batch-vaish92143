{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "NNDL_R7_External.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbDYRk8rzD1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, recall_score, precision_score, f1_score, auc,roc_curve\n",
        "import matplotlib.pyplot as plt   \n",
        "import seaborn as sns\n",
        "%matplotlib inline "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-TVtpskzD1y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Read bank data from csv file\n",
        "my_df = pd.read_csv(\"bank.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDdopjtIzD11",
        "colab_type": "code",
        "colab": {},
        "outputId": "278c146f-374f-4b1b-a21e-cabcdcff6870"
      },
      "source": [
        "my_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>RowNumber</th>\n",
              "      <th>CustomerId</th>\n",
              "      <th>Surname</th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Geography</th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>15634602</td>\n",
              "      <td>Hargrave</td>\n",
              "      <td>619</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>15647311</td>\n",
              "      <td>Hill</td>\n",
              "      <td>608</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>15619304</td>\n",
              "      <td>Onio</td>\n",
              "      <td>502</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>15701354</td>\n",
              "      <td>Boni</td>\n",
              "      <td>699</td>\n",
              "      <td>France</td>\n",
              "      <td>Female</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>15737888</td>\n",
              "      <td>Mitchell</td>\n",
              "      <td>850</td>\n",
              "      <td>Spain</td>\n",
              "      <td>Female</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
              "0          1    15634602  Hargrave          619    France  Female   42   \n",
              "1          2    15647311      Hill          608     Spain  Female   41   \n",
              "2          3    15619304      Onio          502    France  Female   42   \n",
              "3          4    15701354      Boni          699    France  Female   39   \n",
              "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
              "\n",
              "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
              "0       2       0.00              1          1               1   \n",
              "1       1   83807.86              1          0               1   \n",
              "2       8  159660.80              3          1               0   \n",
              "3       1       0.00              2          0               0   \n",
              "4       2  125510.82              1          1               1   \n",
              "\n",
              "   EstimatedSalary  Exited  \n",
              "0        101348.88       1  \n",
              "1        112542.58       0  \n",
              "2        113931.57       1  \n",
              "3         93826.63       0  \n",
              "4         79084.10       0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn19hdCnzD2C",
        "colab_type": "code",
        "colab": {},
        "outputId": "c30baeb8-d3ef-4910-e768-ae8b248a002c"
      },
      "source": [
        "\n",
        "my_df.isnull().values.any()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Wwy2ErFzD2F",
        "colab_type": "text"
      },
      "source": [
        "### 2. Drop the columns which are unique for all users like IDs (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiAGSbWqzD2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "my_df = my_df.drop([\"RowNumber\",\"CustomerId\",\"Surname\"], axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7_92UQkzD2J",
        "colab_type": "code",
        "colab": {},
        "outputId": "4cf5d1f3-c138-4270-cb71-4d178f82c74a"
      },
      "source": [
        "my_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 11)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjyCQ3qIzD2M",
        "colab_type": "text"
      },
      "source": [
        "### 3. Distinguish the feature and target set (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VkXV2mWzD2N",
        "colab_type": "code",
        "colab": {},
        "outputId": "a5fe8872-6b0e-4613-cea5-ed5a43d59ee3"
      },
      "source": [
        "my_df[\"Exited\"].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7963\n",
              "1    2037\n",
              "Name: Exited, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtjmCkEpzD2P",
        "colab_type": "code",
        "colab": {},
        "outputId": "d44417ae-0dae-4b9f-99a0-c219dabc5490"
      },
      "source": [
        "plot = sns.countplot(x = \"Exited\", data = my_df)\n",
        "plot.set_xticklabels(plot.get_xticklabels());"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLDHbm4DzD2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_df = pd.get_dummies(my_df,drop_first=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pilsZP47zD2X",
        "colab_type": "code",
        "colab": {},
        "outputId": "31b7222e-78bd-4117-aea4-dad16aacf8a2"
      },
      "source": [
        "my_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CreditScore</th>\n",
              "      <th>Age</th>\n",
              "      <th>Tenure</th>\n",
              "      <th>Balance</th>\n",
              "      <th>NumOfProducts</th>\n",
              "      <th>HasCrCard</th>\n",
              "      <th>IsActiveMember</th>\n",
              "      <th>EstimatedSalary</th>\n",
              "      <th>Exited</th>\n",
              "      <th>Geography_Germany</th>\n",
              "      <th>Geography_Spain</th>\n",
              "      <th>Gender_Male</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>619</td>\n",
              "      <td>42</td>\n",
              "      <td>2</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>101348.88</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>608</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>83807.86</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>112542.58</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>502</td>\n",
              "      <td>42</td>\n",
              "      <td>8</td>\n",
              "      <td>159660.80</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113931.57</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>699</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>93826.63</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>850</td>\n",
              "      <td>43</td>\n",
              "      <td>2</td>\n",
              "      <td>125510.82</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>79084.10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
              "0          619   42       2       0.00              1          1   \n",
              "1          608   41       1   83807.86              1          0   \n",
              "2          502   42       8  159660.80              3          1   \n",
              "3          699   39       1       0.00              2          0   \n",
              "4          850   43       2  125510.82              1          1   \n",
              "\n",
              "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
              "0               1        101348.88       1                  0   \n",
              "1               1        112542.58       0                  0   \n",
              "2               0        113931.57       1                  0   \n",
              "3               0         93826.63       0                  0   \n",
              "4               1         79084.10       0                  0   \n",
              "\n",
              "   Geography_Spain  Gender_Male  \n",
              "0                0            0  \n",
              "1                1            0  \n",
              "2                0            0  \n",
              "3                0            0  \n",
              "4                1            0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVhen5mfzD2c",
        "colab_type": "text"
      },
      "source": [
        "### 4. Divide the data set into Train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ahm9g-alzD2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X = my_df.drop([\"Exited\"], axis=1)\n",
        "\n",
        "y = my_df[\"Exited\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yg7owxa_zD2g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_size = 0.30 # taking 70:30 training and test set\n",
        "seed = 7  # Random numbmer seeding for reapeatability of the code\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7DcPombzD2q",
        "colab_type": "code",
        "colab": {},
        "outputId": "40d4af9e-bed2-494c-a715-d7755089719c"
      },
      "source": [
        "print(\"Bank Train Data Shape : {0}\".format(X_train.shape))\n",
        "print(\"Bank Test Data Shape : {0}\".format(X_test.shape))\n",
        "print(\"Bank Full Data Shape : {0}\".format(X.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bank Train Data Shape : (7000, 11)\n",
            "Bank Test Data Shape : (3000, 11)\n",
            "Bank Full Data Shape : (10000, 11)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4yArdUPzD2z",
        "colab_type": "text"
      },
      "source": [
        "### 5. Normalize the train and test data (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAY4d7s1zD21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# For NN model it's alway good if we do data normalization\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "transformer = StandardScaler()\n",
        "X_train = transformer.fit_transform(X_train)\n",
        "X_test = transformer.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrNd4egnzD25",
        "colab_type": "text"
      },
      "source": [
        "### 6. Initialize & build the model (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndtldwfzzD27",
        "colab_type": "code",
        "colab": {},
        "outputId": "1056b060-6c85-4c0c-bb8e-566dea4ce940"
      },
      "source": [
        "#Import Tensorflow & Keras Library\n",
        "import tensorflow as tf\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHlUAfPyzD2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "my_model = tf.keras.models.Sequential()\n",
        "\n",
        "my_model.add(tf.keras.layers.Dense(6,  activation='relu', input_shape=(11,)))\n",
        "\n",
        "my_model.add(tf.keras.layers.Dense(6,  activation='relu'))\n",
        "my_model.add( tf.keras.layers.Dense(1,activation='sigmoid', name='output'))\n",
        "\n",
        "my_model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyElMoLJzD3G",
        "colab_type": "code",
        "colab": {},
        "outputId": "0ca49e6d-b4ea-458f-b55f-c078d0fcf1ec"
      },
      "source": [
        "# Fit the model with 100 epochs and batch size 30\n",
        "history =my_model.fit(X_train, y_train,epochs=100,batch_size = 30,validation_data=(X_test, y_test) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0901 22:31:46.787823  4940 deprecation.py:323] From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 7000 samples, validate on 3000 samples\n",
            "Epoch 1/100\n",
            "7000/7000 [==============================] - 2s 222us/sample - loss: 0.5610 - accuracy: 0.7440 - val_loss: 0.4975 - val_accuracy: 0.7977\n",
            "Epoch 2/100\n",
            "7000/7000 [==============================] - 1s 132us/sample - loss: 0.4937 - accuracy: 0.7949 - val_loss: 0.4779 - val_accuracy: 0.8003\n",
            "Epoch 3/100\n",
            "7000/7000 [==============================] - 1s 189us/sample - loss: 0.4786 - accuracy: 0.7954 - val_loss: 0.4643 - val_accuracy: 0.8023\n",
            "Epoch 4/100\n",
            "7000/7000 [==============================] - 1s 185us/sample - loss: 0.4673 - accuracy: 0.7983 - val_loss: 0.4532 - val_accuracy: 0.8077\n",
            "Epoch 5/100\n",
            "7000/7000 [==============================] - 1s 168us/sample - loss: 0.4578 - accuracy: 0.8031 - val_loss: 0.4438 - val_accuracy: 0.8147\n",
            "Epoch 6/100\n",
            "7000/7000 [==============================] - 1s 140us/sample - loss: 0.4499 - accuracy: 0.8059 - val_loss: 0.4361 - val_accuracy: 0.8173\n",
            "Epoch 7/100\n",
            "7000/7000 [==============================] - 1s 134us/sample - loss: 0.4439 - accuracy: 0.8089 - val_loss: 0.4303 - val_accuracy: 0.8203\n",
            "Epoch 8/100\n",
            "7000/7000 [==============================] - 1s 120us/sample - loss: 0.4390 - accuracy: 0.8101 - val_loss: 0.4260 - val_accuracy: 0.8197\n",
            "Epoch 9/100\n",
            "7000/7000 [==============================] - 1s 133us/sample - loss: 0.4351 - accuracy: 0.8111 - val_loss: 0.4229 - val_accuracy: 0.8217\n",
            "Epoch 10/100\n",
            "7000/7000 [==============================] - 1s 98us/sample - loss: 0.4317 - accuracy: 0.8129 - val_loss: 0.4198 - val_accuracy: 0.8197\n",
            "Epoch 11/100\n",
            "7000/7000 [==============================] - 1s 128us/sample - loss: 0.4286 - accuracy: 0.8140 - val_loss: 0.4178 - val_accuracy: 0.8217\n",
            "Epoch 12/100\n",
            "7000/7000 [==============================] - 1s 212us/sample - loss: 0.4258 - accuracy: 0.8126 - val_loss: 0.4157 - val_accuracy: 0.8183\n",
            "Epoch 13/100\n",
            "7000/7000 [==============================] - 1s 135us/sample - loss: 0.4230 - accuracy: 0.8144 - val_loss: 0.4132 - val_accuracy: 0.8200\n",
            "Epoch 14/100\n",
            "7000/7000 [==============================] - 1s 140us/sample - loss: 0.4200 - accuracy: 0.8143 - val_loss: 0.4105 - val_accuracy: 0.8203\n",
            "Epoch 15/100\n",
            "7000/7000 [==============================] - 1s 159us/sample - loss: 0.4168 - accuracy: 0.8161 - val_loss: 0.4079 - val_accuracy: 0.8193\n",
            "Epoch 16/100\n",
            "7000/7000 [==============================] - 1s 143us/sample - loss: 0.4136 - accuracy: 0.8163 - val_loss: 0.4051 - val_accuracy: 0.8223\n",
            "Epoch 17/100\n",
            "7000/7000 [==============================] - 1s 142us/sample - loss: 0.4102 - accuracy: 0.8186 - val_loss: 0.4015 - val_accuracy: 0.8233\n",
            "Epoch 18/100\n",
            "7000/7000 [==============================] - 1s 141us/sample - loss: 0.4066 - accuracy: 0.8196 - val_loss: 0.3980 - val_accuracy: 0.8240\n",
            "Epoch 19/100\n",
            "7000/7000 [==============================] - 1s 118us/sample - loss: 0.4027 - accuracy: 0.8234 - val_loss: 0.3943 - val_accuracy: 0.8270\n",
            "Epoch 20/100\n",
            "7000/7000 [==============================] - 1s 174us/sample - loss: 0.3984 - accuracy: 0.8266 - val_loss: 0.3901 - val_accuracy: 0.8320\n",
            "Epoch 21/100\n",
            "7000/7000 [==============================] - 1s 204us/sample - loss: 0.3940 - accuracy: 0.8274 - val_loss: 0.3860 - val_accuracy: 0.8360\n",
            "Epoch 22/100\n",
            "7000/7000 [==============================] - 1s 151us/sample - loss: 0.3896 - accuracy: 0.8317 - val_loss: 0.3816 - val_accuracy: 0.8377\n",
            "Epoch 23/100\n",
            "7000/7000 [==============================] - 1s 120us/sample - loss: 0.3851 - accuracy: 0.8354 - val_loss: 0.3777 - val_accuracy: 0.8370\n",
            "Epoch 24/100\n",
            "7000/7000 [==============================] - 2s 255us/sample - loss: 0.3806 - accuracy: 0.8371 - val_loss: 0.3735 - val_accuracy: 0.8423\n",
            "Epoch 25/100\n",
            "7000/7000 [==============================] - 1s 156us/sample - loss: 0.3761 - accuracy: 0.8413 - val_loss: 0.3694 - val_accuracy: 0.8483\n",
            "Epoch 26/100\n",
            "7000/7000 [==============================] - 1s 130us/sample - loss: 0.3718 - accuracy: 0.8444 - val_loss: 0.3665 - val_accuracy: 0.8477\n",
            "Epoch 27/100\n",
            "7000/7000 [==============================] - 2s 251us/sample - loss: 0.3684 - accuracy: 0.8456 - val_loss: 0.3628 - val_accuracy: 0.8520\n",
            "Epoch 28/100\n",
            "7000/7000 [==============================] - 2s 225us/sample - loss: 0.3649 - accuracy: 0.8484 - val_loss: 0.3611 - val_accuracy: 0.8543\n",
            "Epoch 29/100\n",
            "7000/7000 [==============================] - 1s 201us/sample - loss: 0.3621 - accuracy: 0.8491 - val_loss: 0.3589 - val_accuracy: 0.8550\n",
            "Epoch 30/100\n",
            "7000/7000 [==============================] - 1s 175us/sample - loss: 0.3597 - accuracy: 0.8519 - val_loss: 0.3595 - val_accuracy: 0.8530\n",
            "Epoch 31/100\n",
            "7000/7000 [==============================] - 1s 114us/sample - loss: 0.3582 - accuracy: 0.8507 - val_loss: 0.3570 - val_accuracy: 0.8553\n",
            "Epoch 32/100\n",
            "7000/7000 [==============================] - 1s 102us/sample - loss: 0.3566 - accuracy: 0.8504 - val_loss: 0.3561 - val_accuracy: 0.8553\n",
            "Epoch 33/100\n",
            "7000/7000 [==============================] - 1s 104us/sample - loss: 0.3556 - accuracy: 0.8514 - val_loss: 0.3558 - val_accuracy: 0.8577\n",
            "Epoch 34/100\n",
            "7000/7000 [==============================] - 1s 109us/sample - loss: 0.3546 - accuracy: 0.8530 - val_loss: 0.3554 - val_accuracy: 0.8587\n",
            "Epoch 35/100\n",
            "7000/7000 [==============================] - 1s 98us/sample - loss: 0.3537 - accuracy: 0.8527 - val_loss: 0.3563 - val_accuracy: 0.8570\n",
            "Epoch 36/100\n",
            "7000/7000 [==============================] - 1s 201us/sample - loss: 0.3531 - accuracy: 0.8540 - val_loss: 0.3548 - val_accuracy: 0.8573\n",
            "Epoch 37/100\n",
            "7000/7000 [==============================] - 1s 169us/sample - loss: 0.3528 - accuracy: 0.8537 - val_loss: 0.3548 - val_accuracy: 0.8573\n",
            "Epoch 38/100\n",
            "7000/7000 [==============================] - 1s 118us/sample - loss: 0.3523 - accuracy: 0.8531 - val_loss: 0.3544 - val_accuracy: 0.8560\n",
            "Epoch 39/100\n",
            "7000/7000 [==============================] - 1s 119us/sample - loss: 0.3518 - accuracy: 0.8549 - val_loss: 0.3545 - val_accuracy: 0.8580\n",
            "Epoch 40/100\n",
            "7000/7000 [==============================] - 1s 128us/sample - loss: 0.3515 - accuracy: 0.8540 - val_loss: 0.3542 - val_accuracy: 0.8573\n",
            "Epoch 41/100\n",
            "7000/7000 [==============================] - 1s 126us/sample - loss: 0.3509 - accuracy: 0.8537 - val_loss: 0.3548 - val_accuracy: 0.8587\n",
            "Epoch 42/100\n",
            "7000/7000 [==============================] - 1s 99us/sample - loss: 0.3506 - accuracy: 0.8556 - val_loss: 0.3543 - val_accuracy: 0.8557\n",
            "Epoch 43/100\n",
            "7000/7000 [==============================] - 1s 80us/sample - loss: 0.3504 - accuracy: 0.8550 - val_loss: 0.3539 - val_accuracy: 0.8590\n",
            "Epoch 44/100\n",
            "7000/7000 [==============================] - 0s 63us/sample - loss: 0.3498 - accuracy: 0.8544 - val_loss: 0.3541 - val_accuracy: 0.8593\n",
            "Epoch 45/100\n",
            "7000/7000 [==============================] - 0s 64us/sample - loss: 0.3497 - accuracy: 0.8536 - val_loss: 0.3535 - val_accuracy: 0.8600\n",
            "Epoch 46/100\n",
            "7000/7000 [==============================] - 0s 69us/sample - loss: 0.3493 - accuracy: 0.8541 - val_loss: 0.3537 - val_accuracy: 0.8593\n",
            "Epoch 47/100\n",
            "7000/7000 [==============================] - 2s 223us/sample - loss: 0.3493 - accuracy: 0.8547 - val_loss: 0.3533 - val_accuracy: 0.8597\n",
            "Epoch 48/100\n",
            "7000/7000 [==============================] - 1s 145us/sample - loss: 0.3489 - accuracy: 0.8564 - val_loss: 0.3534 - val_accuracy: 0.8597\n",
            "Epoch 49/100\n",
            "7000/7000 [==============================] - 1s 211us/sample - loss: 0.3487 - accuracy: 0.8560 - val_loss: 0.3538 - val_accuracy: 0.8580\n",
            "Epoch 50/100\n",
            "7000/7000 [==============================] - 1s 152us/sample - loss: 0.3483 - accuracy: 0.8553 - val_loss: 0.3548 - val_accuracy: 0.8570\n",
            "Epoch 51/100\n",
            "7000/7000 [==============================] - 1s 151us/sample - loss: 0.3484 - accuracy: 0.8541 - val_loss: 0.3517 - val_accuracy: 0.8590\n",
            "Epoch 52/100\n",
            "7000/7000 [==============================] - 1s 119us/sample - loss: 0.3480 - accuracy: 0.8550 - val_loss: 0.3516 - val_accuracy: 0.8607\n",
            "Epoch 53/100\n",
            "7000/7000 [==============================] - 1s 110us/sample - loss: 0.3480 - accuracy: 0.8566 - val_loss: 0.3520 - val_accuracy: 0.8607\n",
            "Epoch 54/100\n",
            "7000/7000 [==============================] - 1s 123us/sample - loss: 0.3476 - accuracy: 0.8560 - val_loss: 0.3515 - val_accuracy: 0.8600\n",
            "Epoch 55/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "7000/7000 [==============================] - 1s 146us/sample - loss: 0.3475 - accuracy: 0.8559 - val_loss: 0.3513 - val_accuracy: 0.8570\n",
            "Epoch 56/100\n",
            "7000/7000 [==============================] - 2s 218us/sample - loss: 0.3474 - accuracy: 0.8569 - val_loss: 0.3512 - val_accuracy: 0.8597\n",
            "Epoch 57/100\n",
            "7000/7000 [==============================] - 2s 221us/sample - loss: 0.3472 - accuracy: 0.8564 - val_loss: 0.3513 - val_accuracy: 0.8590\n",
            "Epoch 58/100\n",
            "7000/7000 [==============================] - 2s 260us/sample - loss: 0.3468 - accuracy: 0.8554 - val_loss: 0.3525 - val_accuracy: 0.8573\n",
            "Epoch 59/100\n",
            "7000/7000 [==============================] - 1s 169us/sample - loss: 0.3467 - accuracy: 0.8584 - val_loss: 0.3525 - val_accuracy: 0.8580\n",
            "Epoch 60/100\n",
            "7000/7000 [==============================] - 2s 226us/sample - loss: 0.3465 - accuracy: 0.8563 - val_loss: 0.3510 - val_accuracy: 0.8583\n",
            "Epoch 61/100\n",
            "7000/7000 [==============================] - 2s 224us/sample - loss: 0.3465 - accuracy: 0.8554 - val_loss: 0.3503 - val_accuracy: 0.8577\n",
            "Epoch 62/100\n",
            "7000/7000 [==============================] - 2s 257us/sample - loss: 0.3463 - accuracy: 0.8566 - val_loss: 0.3500 - val_accuracy: 0.8583\n",
            "Epoch 63/100\n",
            "7000/7000 [==============================] - 1s 158us/sample - loss: 0.3461 - accuracy: 0.8561 - val_loss: 0.3506 - val_accuracy: 0.8613\n",
            "Epoch 64/100\n",
            "7000/7000 [==============================] - 1s 210us/sample - loss: 0.3459 - accuracy: 0.8579 - val_loss: 0.3518 - val_accuracy: 0.8563\n",
            "Epoch 65/100\n",
            "7000/7000 [==============================] - 1s 152us/sample - loss: 0.3462 - accuracy: 0.8574 - val_loss: 0.3499 - val_accuracy: 0.8567\n",
            "Epoch 66/100\n",
            "7000/7000 [==============================] - 1s 136us/sample - loss: 0.3456 - accuracy: 0.8579 - val_loss: 0.3508 - val_accuracy: 0.8610\n",
            "Epoch 67/100\n",
            "7000/7000 [==============================] - 1s 144us/sample - loss: 0.3458 - accuracy: 0.8580 - val_loss: 0.3502 - val_accuracy: 0.8583\n",
            "Epoch 68/100\n",
            "7000/7000 [==============================] - 1s 124us/sample - loss: 0.3454 - accuracy: 0.8581 - val_loss: 0.3501 - val_accuracy: 0.8560\n",
            "Epoch 69/100\n",
            "7000/7000 [==============================] - 1s 88us/sample - loss: 0.3456 - accuracy: 0.8583 - val_loss: 0.3493 - val_accuracy: 0.8603\n",
            "Epoch 70/100\n",
            "7000/7000 [==============================] - 1s 87us/sample - loss: 0.3455 - accuracy: 0.8577 - val_loss: 0.3494 - val_accuracy: 0.8580\n",
            "Epoch 71/100\n",
            "7000/7000 [==============================] - 2s 224us/sample - loss: 0.3454 - accuracy: 0.8574 - val_loss: 0.3494 - val_accuracy: 0.8603\n",
            "Epoch 72/100\n",
            "7000/7000 [==============================] - 1s 170us/sample - loss: 0.3453 - accuracy: 0.8581 - val_loss: 0.3494 - val_accuracy: 0.8600\n",
            "Epoch 73/100\n",
            "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3450 - accuracy: 0.8587 - val_loss: 0.3494 - val_accuracy: 0.8617\n",
            "Epoch 74/100\n",
            "7000/7000 [==============================] - 1s 130us/sample - loss: 0.3450 - accuracy: 0.8557 - val_loss: 0.3487 - val_accuracy: 0.8577\n",
            "Epoch 75/100\n",
            "7000/7000 [==============================] - 1s 146us/sample - loss: 0.3449 - accuracy: 0.8574 - val_loss: 0.3488 - val_accuracy: 0.8627\n",
            "Epoch 76/100\n",
            "7000/7000 [==============================] - 1s 105us/sample - loss: 0.3450 - accuracy: 0.8571 - val_loss: 0.3482 - val_accuracy: 0.8603\n",
            "Epoch 77/100\n",
            "7000/7000 [==============================] - 2s 233us/sample - loss: 0.3445 - accuracy: 0.8583 - val_loss: 0.3484 - val_accuracy: 0.8623\n",
            "Epoch 78/100\n",
            "7000/7000 [==============================] - 1s 192us/sample - loss: 0.3443 - accuracy: 0.8579 - val_loss: 0.3483 - val_accuracy: 0.8597\n",
            "Epoch 79/100\n",
            "7000/7000 [==============================] - 2s 242us/sample - loss: 0.3442 - accuracy: 0.8589 - val_loss: 0.3482 - val_accuracy: 0.8610\n",
            "Epoch 80/100\n",
            "7000/7000 [==============================] - 1s 131us/sample - loss: 0.3442 - accuracy: 0.8581 - val_loss: 0.3487 - val_accuracy: 0.8617\n",
            "Epoch 81/100\n",
            "7000/7000 [==============================] - 1s 123us/sample - loss: 0.3441 - accuracy: 0.8570 - val_loss: 0.3483 - val_accuracy: 0.8613\n",
            "Epoch 82/100\n",
            "7000/7000 [==============================] - 1s 103us/sample - loss: 0.3440 - accuracy: 0.8567 - val_loss: 0.3481 - val_accuracy: 0.8617\n",
            "Epoch 83/100\n",
            "7000/7000 [==============================] - 2s 229us/sample - loss: 0.3440 - accuracy: 0.8553 - val_loss: 0.3479 - val_accuracy: 0.8593\n",
            "Epoch 84/100\n",
            "7000/7000 [==============================] - 1s 170us/sample - loss: 0.3435 - accuracy: 0.8581 - val_loss: 0.3489 - val_accuracy: 0.8610\n",
            "Epoch 85/100\n",
            "7000/7000 [==============================] - 1s 151us/sample - loss: 0.3439 - accuracy: 0.8584 - val_loss: 0.3485 - val_accuracy: 0.8600\n",
            "Epoch 86/100\n",
            "7000/7000 [==============================] - 1s 130us/sample - loss: 0.3438 - accuracy: 0.8563 - val_loss: 0.3475 - val_accuracy: 0.8613\n",
            "Epoch 87/100\n",
            "7000/7000 [==============================] - 1s 116us/sample - loss: 0.3433 - accuracy: 0.8589 - val_loss: 0.3480 - val_accuracy: 0.8623\n",
            "Epoch 88/100\n",
            "7000/7000 [==============================] - 1s 111us/sample - loss: 0.3435 - accuracy: 0.8569 - val_loss: 0.3478 - val_accuracy: 0.8613\n",
            "Epoch 89/100\n",
            "7000/7000 [==============================] - 2s 219us/sample - loss: 0.3434 - accuracy: 0.8600 - val_loss: 0.3473 - val_accuracy: 0.8603\n",
            "Epoch 90/100\n",
            "7000/7000 [==============================] - 1s 169us/sample - loss: 0.3433 - accuracy: 0.8574 - val_loss: 0.3473 - val_accuracy: 0.8613\n",
            "Epoch 91/100\n",
            "7000/7000 [==============================] - 1s 162us/sample - loss: 0.3433 - accuracy: 0.8581 - val_loss: 0.3475 - val_accuracy: 0.8590\n",
            "Epoch 92/100\n",
            "7000/7000 [==============================] - 1s 134us/sample - loss: 0.3428 - accuracy: 0.8573 - val_loss: 0.3480 - val_accuracy: 0.8607\n",
            "Epoch 93/100\n",
            "7000/7000 [==============================] - 1s 105us/sample - loss: 0.3427 - accuracy: 0.8574 - val_loss: 0.3480 - val_accuracy: 0.8620\n",
            "Epoch 94/100\n",
            "7000/7000 [==============================] - 1s 115us/sample - loss: 0.3425 - accuracy: 0.8584 - val_loss: 0.3485 - val_accuracy: 0.8620\n",
            "Epoch 95/100\n",
            "7000/7000 [==============================] - 1s 129us/sample - loss: 0.3426 - accuracy: 0.8589 - val_loss: 0.3475 - val_accuracy: 0.8550\n",
            "Epoch 96/100\n",
            "7000/7000 [==============================] - 1s 102us/sample - loss: 0.3424 - accuracy: 0.8581 - val_loss: 0.3462 - val_accuracy: 0.8603\n",
            "Epoch 97/100\n",
            "7000/7000 [==============================] - 1s 94us/sample - loss: 0.3421 - accuracy: 0.8589 - val_loss: 0.3470 - val_accuracy: 0.8603\n",
            "Epoch 98/100\n",
            "7000/7000 [==============================] - 2s 275us/sample - loss: 0.3423 - accuracy: 0.8579 - val_loss: 0.3475 - val_accuracy: 0.8623\n",
            "Epoch 99/100\n",
            "7000/7000 [==============================] - 1s 189us/sample - loss: 0.3424 - accuracy: 0.8580 - val_loss: 0.3479 - val_accuracy: 0.8617\n",
            "Epoch 100/100\n",
            "7000/7000 [==============================] - 1s 96us/sample - loss: 0.3426 - accuracy: 0.8577 - val_loss: 0.3460 - val_accuracy: 0.8617\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyFDBeJYzD3L",
        "colab_type": "text"
      },
      "source": [
        "### 7. Optimize the model (Optional)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvVeMLbfzD3N",
        "colab_type": "text"
      },
      "source": [
        "### Build the Model with Adam optimizer and early stop which help  for model to protect from overfitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbTSVaEhzD3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "Opt_mymodel = tf.keras.models.Sequential()\n",
        "\n",
        "Opt_mymodel.add(tf.keras.layers.Dense(6,  activation='relu', input_shape=(11,)))\n",
        "\n",
        "Opt_mymodel.add(tf.keras.layers.Dense(6,  activation='relu'))\n",
        "Opt_mymodel.add( tf.keras.layers.Dense(1,activation='sigmoid', name='output'))\n",
        "\n",
        "Opt_mymodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS0Dg-yJzD3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "earlyStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F93EX2-MzD3X",
        "colab_type": "code",
        "colab": {},
        "outputId": "104342e6-5047-4f3b-c6d0-fcb411e7e487"
      },
      "source": [
        "history =Opt_mymodel.fit(X_train, y_train, \n",
        "          validation_data=(X_train, y_train), \n",
        "          epochs=300,\n",
        "          batch_size=32,\n",
        "          callbacks=[earlyStop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 7000 samples, validate on 7000 samples\n",
            "Epoch 1/300\n",
            "7000/7000 [==============================] - 3s 382us/sample - loss: 0.5279 - accuracy: 0.7716 - val_loss: 0.4744 - val_accuracy: 0.7954\n",
            "Epoch 2/300\n",
            "7000/7000 [==============================] - 1s 181us/sample - loss: 0.4599 - accuracy: 0.7954 - val_loss: 0.4494 - val_accuracy: 0.7954\n",
            "Epoch 3/300\n",
            "7000/7000 [==============================] - 1s 164us/sample - loss: 0.4450 - accuracy: 0.7954 - val_loss: 0.4398 - val_accuracy: 0.7954\n",
            "Epoch 4/300\n",
            "7000/7000 [==============================] - 2s 315us/sample - loss: 0.4377 - accuracy: 0.7954 - val_loss: 0.4341 - val_accuracy: 0.7954\n",
            "Epoch 5/300\n",
            "7000/7000 [==============================] - 2s 279us/sample - loss: 0.4326 - accuracy: 0.7954 - val_loss: 0.4290 - val_accuracy: 0.7954\n",
            "Epoch 6/300\n",
            "7000/7000 [==============================] - 2s 246us/sample - loss: 0.4279 - accuracy: 0.7960 - val_loss: 0.4248 - val_accuracy: 0.7979\n",
            "Epoch 7/300\n",
            "7000/7000 [==============================] - 2s 314us/sample - loss: 0.4241 - accuracy: 0.8023 - val_loss: 0.4211 - val_accuracy: 0.8060\n",
            "Epoch 8/300\n",
            "7000/7000 [==============================] - 2s 309us/sample - loss: 0.4206 - accuracy: 0.8119 - val_loss: 0.4179 - val_accuracy: 0.8151\n",
            "Epoch 9/300\n",
            "7000/7000 [==============================] - 2s 237us/sample - loss: 0.4174 - accuracy: 0.8186 - val_loss: 0.4146 - val_accuracy: 0.8206\n",
            "Epoch 10/300\n",
            "7000/7000 [==============================] - 1s 163us/sample - loss: 0.4143 - accuracy: 0.8241 - val_loss: 0.4118 - val_accuracy: 0.8276\n",
            "Epoch 11/300\n",
            "7000/7000 [==============================] - 2s 326us/sample - loss: 0.4118 - accuracy: 0.8289 - val_loss: 0.4096 - val_accuracy: 0.8296\n",
            "Epoch 12/300\n",
            "7000/7000 [==============================] - 2s 306us/sample - loss: 0.4097 - accuracy: 0.8284 - val_loss: 0.4076 - val_accuracy: 0.8291\n",
            "Epoch 13/300\n",
            "7000/7000 [==============================] - 2s 290us/sample - loss: 0.4079 - accuracy: 0.8316 - val_loss: 0.4057 - val_accuracy: 0.8324\n",
            "Epoch 14/300\n",
            "7000/7000 [==============================] - 1s 184us/sample - loss: 0.4063 - accuracy: 0.8320 - val_loss: 0.4040 - val_accuracy: 0.8320\n",
            "Epoch 15/300\n",
            "7000/7000 [==============================] - 1s 148us/sample - loss: 0.4047 - accuracy: 0.8316 - val_loss: 0.4024 - val_accuracy: 0.8327\n",
            "Epoch 16/300\n",
            "7000/7000 [==============================] - 1s 155us/sample - loss: 0.4033 - accuracy: 0.8316 - val_loss: 0.4009 - val_accuracy: 0.8324\n",
            "Epoch 17/300\n",
            "7000/7000 [==============================] - 1s 130us/sample - loss: 0.4016 - accuracy: 0.8317 - val_loss: 0.3994 - val_accuracy: 0.8336\n",
            "Epoch 18/300\n",
            "7000/7000 [==============================] - 1s 149us/sample - loss: 0.4000 - accuracy: 0.8326 - val_loss: 0.3978 - val_accuracy: 0.8323\n",
            "Epoch 19/300\n",
            "7000/7000 [==============================] - 2s 301us/sample - loss: 0.3984 - accuracy: 0.8301 - val_loss: 0.3964 - val_accuracy: 0.8324\n",
            "Epoch 20/300\n",
            "7000/7000 [==============================] - 2s 282us/sample - loss: 0.3972 - accuracy: 0.8314 - val_loss: 0.3950 - val_accuracy: 0.8317\n",
            "Epoch 21/300\n",
            "7000/7000 [==============================] - 1s 205us/sample - loss: 0.3958 - accuracy: 0.8303 - val_loss: 0.3935 - val_accuracy: 0.8314\n",
            "Epoch 22/300\n",
            "7000/7000 [==============================] - 2s 282us/sample - loss: 0.3943 - accuracy: 0.8310 - val_loss: 0.3920 - val_accuracy: 0.8314\n",
            "Epoch 23/300\n",
            "7000/7000 [==============================] - 1s 211us/sample - loss: 0.3928 - accuracy: 0.8301 - val_loss: 0.3907 - val_accuracy: 0.8307\n",
            "Epoch 24/300\n",
            "7000/7000 [==============================] - 2s 354us/sample - loss: 0.3914 - accuracy: 0.8286 - val_loss: 0.3893 - val_accuracy: 0.8304\n",
            "Epoch 25/300\n",
            "7000/7000 [==============================] - 2s 261us/sample - loss: 0.3901 - accuracy: 0.8299 - val_loss: 0.3878 - val_accuracy: 0.8311\n",
            "Epoch 26/300\n",
            "7000/7000 [==============================] - 3s 384us/sample - loss: 0.3885 - accuracy: 0.8316 - val_loss: 0.3860 - val_accuracy: 0.8316\n",
            "Epoch 27/300\n",
            "7000/7000 [==============================] - 2s 229us/sample - loss: 0.3869 - accuracy: 0.8323 - val_loss: 0.3843 - val_accuracy: 0.8327\n",
            "Epoch 28/300\n",
            "7000/7000 [==============================] - 1s 178us/sample - loss: 0.3850 - accuracy: 0.8341 - val_loss: 0.3823 - val_accuracy: 0.8353\n",
            "Epoch 29/300\n",
            "7000/7000 [==============================] - 1s 153us/sample - loss: 0.3825 - accuracy: 0.8359 - val_loss: 0.3800 - val_accuracy: 0.8386\n",
            "Epoch 30/300\n",
            "7000/7000 [==============================] - 2s 317us/sample - loss: 0.3804 - accuracy: 0.8384 - val_loss: 0.3772 - val_accuracy: 0.8414\n",
            "Epoch 31/300\n",
            "7000/7000 [==============================] - 2s 284us/sample - loss: 0.3776 - accuracy: 0.8416 - val_loss: 0.3746 - val_accuracy: 0.8429\n",
            "Epoch 32/300\n",
            "7000/7000 [==============================] - 2s 284us/sample - loss: 0.3741 - accuracy: 0.8450 - val_loss: 0.3698 - val_accuracy: 0.8471\n",
            "Epoch 33/300\n",
            "7000/7000 [==============================] - 2s 274us/sample - loss: 0.3690 - accuracy: 0.8463 - val_loss: 0.3650 - val_accuracy: 0.8501\n",
            "Epoch 34/300\n",
            "7000/7000 [==============================] - 2s 271us/sample - loss: 0.3644 - accuracy: 0.8513 - val_loss: 0.3599 - val_accuracy: 0.8529\n",
            "Epoch 35/300\n",
            "7000/7000 [==============================] - 2s 286us/sample - loss: 0.3600 - accuracy: 0.8544 - val_loss: 0.3561 - val_accuracy: 0.8571\n",
            "Epoch 36/300\n",
            "7000/7000 [==============================] - 2s 252us/sample - loss: 0.3562 - accuracy: 0.8559 - val_loss: 0.3530 - val_accuracy: 0.8579\n",
            "Epoch 37/300\n",
            "7000/7000 [==============================] - 2s 263us/sample - loss: 0.3536 - accuracy: 0.8577 - val_loss: 0.3505 - val_accuracy: 0.8586\n",
            "Epoch 38/300\n",
            "7000/7000 [==============================] - 1s 201us/sample - loss: 0.3514 - accuracy: 0.8593 - val_loss: 0.3485 - val_accuracy: 0.8607\n",
            "Epoch 39/300\n",
            "7000/7000 [==============================] - 1s 161us/sample - loss: 0.3499 - accuracy: 0.8593 - val_loss: 0.3472 - val_accuracy: 0.8604\n",
            "Epoch 40/300\n",
            "7000/7000 [==============================] - 2s 249us/sample - loss: 0.3485 - accuracy: 0.8604 - val_loss: 0.3463 - val_accuracy: 0.8601\n",
            "Epoch 41/300\n",
            "7000/7000 [==============================] - 1s 203us/sample - loss: 0.3476 - accuracy: 0.8597 - val_loss: 0.3452 - val_accuracy: 0.8600\n",
            "Epoch 42/300\n",
            "7000/7000 [==============================] - 1s 202us/sample - loss: 0.3468 - accuracy: 0.8593 - val_loss: 0.3454 - val_accuracy: 0.8607\n",
            "Epoch 43/300\n",
            "7000/7000 [==============================] - 1s 145us/sample - loss: 0.3459 - accuracy: 0.8607 - val_loss: 0.3434 - val_accuracy: 0.8607\n",
            "Epoch 44/300\n",
            "7000/7000 [==============================] - 1s 123us/sample - loss: 0.3451 - accuracy: 0.8606 - val_loss: 0.3426 - val_accuracy: 0.8624\n",
            "Epoch 45/300\n",
            "7000/7000 [==============================] - 1s 88us/sample - loss: 0.3443 - accuracy: 0.8609 - val_loss: 0.3418 - val_accuracy: 0.8616\n",
            "Epoch 46/300\n",
            "7000/7000 [==============================] - 1s 90us/sample - loss: 0.3435 - accuracy: 0.8607 - val_loss: 0.3412 - val_accuracy: 0.8611\n",
            "Epoch 47/300\n",
            "7000/7000 [==============================] - 1s 80us/sample - loss: 0.3429 - accuracy: 0.8603 - val_loss: 0.3408 - val_accuracy: 0.8620\n",
            "Epoch 48/300\n",
            "7000/7000 [==============================] - 1s 77us/sample - loss: 0.3423 - accuracy: 0.8610 - val_loss: 0.3400 - val_accuracy: 0.8617\n",
            "Epoch 49/300\n",
            "7000/7000 [==============================] - 1s 77us/sample - loss: 0.3415 - accuracy: 0.8589 - val_loss: 0.3399 - val_accuracy: 0.8596\n",
            "Epoch 50/300\n",
            "7000/7000 [==============================] - 1s 79us/sample - loss: 0.3414 - accuracy: 0.8603 - val_loss: 0.3390 - val_accuracy: 0.8613\n",
            "Epoch 51/300\n",
            "7000/7000 [==============================] - 1s 87us/sample - loss: 0.3407 - accuracy: 0.8607 - val_loss: 0.3388 - val_accuracy: 0.8610\n",
            "Epoch 52/300\n",
            "7000/7000 [==============================] - 1s 79us/sample - loss: 0.3404 - accuracy: 0.8594 - val_loss: 0.3382 - val_accuracy: 0.8607\n",
            "Epoch 53/300\n",
            "7000/7000 [==============================] - 1s 77us/sample - loss: 0.3398 - accuracy: 0.8599 - val_loss: 0.3379 - val_accuracy: 0.8610\n",
            "Epoch 54/300\n",
            "7000/7000 [==============================] - 1s 77us/sample - loss: 0.3397 - accuracy: 0.8596 - val_loss: 0.3373 - val_accuracy: 0.8611\n",
            "Epoch 55/300\n",
            "7000/7000 [==============================] - 1s 78us/sample - loss: 0.3392 - accuracy: 0.8591 - val_loss: 0.3370 - val_accuracy: 0.8617\n",
            "Epoch 56/300\n",
            "7000/7000 [==============================] - 1s 80us/sample - loss: 0.3390 - accuracy: 0.8606 - val_loss: 0.3371 - val_accuracy: 0.8614\n",
            "Epoch 57/300\n",
            "7000/7000 [==============================] - 1s 75us/sample - loss: 0.3389 - accuracy: 0.8587 - val_loss: 0.3365 - val_accuracy: 0.8611\n",
            "Epoch 58/300\n",
            "7000/7000 [==============================] - 1s 77us/sample - loss: 0.3381 - accuracy: 0.8613 - val_loss: 0.3368 - val_accuracy: 0.8606\n",
            "Epoch 59/300\n",
            "7000/7000 [==============================] - 1s 75us/sample - loss: 0.3381 - accuracy: 0.8620 - val_loss: 0.3359 - val_accuracy: 0.8607\n",
            "Epoch 60/300\n",
            "7000/7000 [==============================] - 1s 84us/sample - loss: 0.3378 - accuracy: 0.8606 - val_loss: 0.3360 - val_accuracy: 0.8593\n",
            "Epoch 61/300\n",
            "7000/7000 [==============================] - 2s 302us/sample - loss: 0.3378 - accuracy: 0.8601 - val_loss: 0.3358 - val_accuracy: 0.8613\n",
            "Epoch 62/300\n",
            "7000/7000 [==============================] - 1s 205us/sample - loss: 0.3375 - accuracy: 0.8600 - val_loss: 0.3351 - val_accuracy: 0.8624\n",
            "Epoch 63/300\n",
            "7000/7000 [==============================] - 1s 173us/sample - loss: 0.3376 - accuracy: 0.8614 - val_loss: 0.3352 - val_accuracy: 0.8606\n",
            "Epoch 64/300\n",
            "7000/7000 [==============================] - 1s 154us/sample - loss: 0.3370 - accuracy: 0.8603 - val_loss: 0.3348 - val_accuracy: 0.8627\n",
            "Epoch 65/300\n",
            "7000/7000 [==============================] - 2s 291us/sample - loss: 0.3366 - accuracy: 0.8603 - val_loss: 0.3346 - val_accuracy: 0.8637\n",
            "Epoch 66/300\n",
            "7000/7000 [==============================] - 2s 311us/sample - loss: 0.3363 - accuracy: 0.8611 - val_loss: 0.3346 - val_accuracy: 0.8621\n",
            "Epoch 67/300\n",
            "7000/7000 [==============================] - 1s 181us/sample - loss: 0.3366 - accuracy: 0.8616 - val_loss: 0.3340 - val_accuracy: 0.8610\n",
            "Epoch 68/300\n",
            "7000/7000 [==============================] - 1s 144us/sample - loss: 0.3361 - accuracy: 0.8611 - val_loss: 0.3339 - val_accuracy: 0.8629\n",
            "Epoch 69/300\n",
            "7000/7000 [==============================] - 2s 327us/sample - loss: 0.3357 - accuracy: 0.8607 - val_loss: 0.3339 - val_accuracy: 0.8624\n",
            "Epoch 70/300\n",
            "7000/7000 [==============================] - 1s 169us/sample - loss: 0.3357 - accuracy: 0.8619 - val_loss: 0.3336 - val_accuracy: 0.8617\n",
            "Epoch 71/300\n",
            "7000/7000 [==============================] - 1s 150us/sample - loss: 0.3357 - accuracy: 0.8620 - val_loss: 0.3333 - val_accuracy: 0.8630\n",
            "Epoch 72/300\n",
            "7000/7000 [==============================] - 2s 329us/sample - loss: 0.3353 - accuracy: 0.8623 - val_loss: 0.3337 - val_accuracy: 0.8624\n",
            "Epoch 73/300\n",
            "7000/7000 [==============================] - 2s 293us/sample - loss: 0.3357 - accuracy: 0.8626 - val_loss: 0.3330 - val_accuracy: 0.8617\n",
            "Epoch 74/300\n",
            "7000/7000 [==============================] - 1s 171us/sample - loss: 0.3351 - accuracy: 0.8617 - val_loss: 0.3329 - val_accuracy: 0.8644\n",
            "Epoch 75/300\n",
            "7000/7000 [==============================] - 2s 326us/sample - loss: 0.3348 - accuracy: 0.8626 - val_loss: 0.3325 - val_accuracy: 0.8637\n",
            "Epoch 76/300\n",
            "7000/7000 [==============================] - 1s 184us/sample - loss: 0.3345 - accuracy: 0.8629 - val_loss: 0.3325 - val_accuracy: 0.8630\n",
            "Epoch 77/300\n",
            "7000/7000 [==============================] - 2s 276us/sample - loss: 0.3344 - accuracy: 0.8623 - val_loss: 0.3326 - val_accuracy: 0.8636\n",
            "Epoch 78/300\n",
            "7000/7000 [==============================] - 2s 313us/sample - loss: 0.3339 - accuracy: 0.8617 - val_loss: 0.3321 - val_accuracy: 0.8639\n",
            "Epoch 79/300\n",
            "7000/7000 [==============================] - 1s 203us/sample - loss: 0.3339 - accuracy: 0.8634 - val_loss: 0.3318 - val_accuracy: 0.8637\n",
            "Epoch 80/300\n",
            "7000/7000 [==============================] - 1s 137us/sample - loss: 0.3341 - accuracy: 0.8630 - val_loss: 0.3315 - val_accuracy: 0.8650\n",
            "Epoch 81/300\n",
            "7000/7000 [==============================] - 2s 287us/sample - loss: 0.3332 - accuracy: 0.8643 - val_loss: 0.3312 - val_accuracy: 0.8643\n",
            "Epoch 82/300\n",
            "7000/7000 [==============================] - 2s 276us/sample - loss: 0.3328 - accuracy: 0.8631 - val_loss: 0.3317 - val_accuracy: 0.8651\n",
            "Epoch 83/300\n",
            "7000/7000 [==============================] - 2s 274us/sample - loss: 0.3333 - accuracy: 0.8634 - val_loss: 0.3310 - val_accuracy: 0.8654\n",
            "Epoch 84/300\n",
            "7000/7000 [==============================] - 1s 177us/sample - loss: 0.3329 - accuracy: 0.8640 - val_loss: 0.3307 - val_accuracy: 0.8621\n",
            "Epoch 85/300\n",
            "7000/7000 [==============================] - 1s 181us/sample - loss: 0.3328 - accuracy: 0.8630 - val_loss: 0.3305 - val_accuracy: 0.8640\n",
            "Epoch 86/300\n",
            "7000/7000 [==============================] - 2s 263us/sample - loss: 0.3327 - accuracy: 0.8649 - val_loss: 0.3304 - val_accuracy: 0.8647\n",
            "Epoch 87/300\n",
            "7000/7000 [==============================] - 1s 170us/sample - loss: 0.3322 - accuracy: 0.8627 - val_loss: 0.3301 - val_accuracy: 0.8646\n",
            "Epoch 88/300\n",
            "7000/7000 [==============================] - 2s 289us/sample - loss: 0.3319 - accuracy: 0.8657 - val_loss: 0.3302 - val_accuracy: 0.8651\n",
            "Epoch 89/300\n",
            "7000/7000 [==============================] - 2s 277us/sample - loss: 0.3320 - accuracy: 0.8657 - val_loss: 0.3299 - val_accuracy: 0.8641\n",
            "Epoch 90/300\n",
            "7000/7000 [==============================] - 1s 185us/sample - loss: 0.3320 - accuracy: 0.8644 - val_loss: 0.3299 - val_accuracy: 0.8643\n",
            "Epoch 91/300\n",
            "7000/7000 [==============================] - 1s 178us/sample - loss: 0.3316 - accuracy: 0.8654 - val_loss: 0.3306 - val_accuracy: 0.8661\n",
            "Epoch 92/300\n",
            "7000/7000 [==============================] - 1s 125us/sample - loss: 0.3322 - accuracy: 0.8646 - val_loss: 0.3300 - val_accuracy: 0.8647\n",
            "Epoch 93/300\n",
            "7000/7000 [==============================] - 1s 175us/sample - loss: 0.3317 - accuracy: 0.8637 - val_loss: 0.3298 - val_accuracy: 0.8651\n",
            "Epoch 94/300\n",
            "7000/7000 [==============================] - 2s 259us/sample - loss: 0.3317 - accuracy: 0.8640 - val_loss: 0.3295 - val_accuracy: 0.8656\n",
            "Epoch 95/300\n",
            "7000/7000 [==============================] - 2s 280us/sample - loss: 0.3316 - accuracy: 0.8647 - val_loss: 0.3293 - val_accuracy: 0.8640\n",
            "Epoch 96/300\n",
            "7000/7000 [==============================] - 2s 234us/sample - loss: 0.3313 - accuracy: 0.8646 - val_loss: 0.3292 - val_accuracy: 0.8654\n",
            "Epoch 97/300\n",
            "7000/7000 [==============================] - 1s 173us/sample - loss: 0.3314 - accuracy: 0.8640 - val_loss: 0.3293 - val_accuracy: 0.8651\n",
            "Epoch 98/300\n",
            "7000/7000 [==============================] - 1s 163us/sample - loss: 0.3312 - accuracy: 0.8651 - val_loss: 0.3292 - val_accuracy: 0.8653\n",
            "Epoch 99/300\n",
            "7000/7000 [==============================] - 1s 152us/sample - loss: 0.3308 - accuracy: 0.8633 - val_loss: 0.3294 - val_accuracy: 0.8666\n",
            "Epoch 100/300\n",
            "7000/7000 [==============================] - 1s 127us/sample - loss: 0.3311 - accuracy: 0.8660 - val_loss: 0.3288 - val_accuracy: 0.8656\n",
            "Epoch 101/300\n",
            "7000/7000 [==============================] - 2s 291us/sample - loss: 0.3311 - accuracy: 0.8647 - val_loss: 0.3289 - val_accuracy: 0.8643\n",
            "Epoch 102/300\n",
            "7000/7000 [==============================] - 1s 213us/sample - loss: 0.3309 - accuracy: 0.8649 - val_loss: 0.3291 - val_accuracy: 0.8660\n",
            "Epoch 103/300\n",
            "7000/7000 [==============================] - 1s 138us/sample - loss: 0.3310 - accuracy: 0.8657 - val_loss: 0.3286 - val_accuracy: 0.8644\n",
            "Epoch 104/300\n",
            "7000/7000 [==============================] - 2s 270us/sample - loss: 0.3307 - accuracy: 0.8646 - val_loss: 0.3286 - val_accuracy: 0.8659\n",
            "Epoch 105/300\n",
            "7000/7000 [==============================] - 2s 226us/sample - loss: 0.3310 - accuracy: 0.8650 - val_loss: 0.3286 - val_accuracy: 0.8666\n",
            "Epoch 106/300\n",
            "7000/7000 [==============================] - 1s 160us/sample - loss: 0.3310 - accuracy: 0.8660 - val_loss: 0.3287 - val_accuracy: 0.8656\n",
            "Epoch 107/300\n",
            "7000/7000 [==============================] - 1s 144us/sample - loss: 0.3304 - accuracy: 0.8660 - val_loss: 0.3288 - val_accuracy: 0.8653\n",
            "Epoch 108/300\n",
            "7000/7000 [==============================] - 1s 140us/sample - loss: 0.3305 - accuracy: 0.8644 - val_loss: 0.3282 - val_accuracy: 0.8664\n",
            "Epoch 109/300\n",
            "7000/7000 [==============================] - 1s 145us/sample - loss: 0.3306 - accuracy: 0.8651 - val_loss: 0.3284 - val_accuracy: 0.8650\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 110/300\n",
            "7000/7000 [==============================] - 2s 274us/sample - loss: 0.3303 - accuracy: 0.8649 - val_loss: 0.3288 - val_accuracy: 0.8660\n",
            "Epoch 111/300\n",
            "7000/7000 [==============================] - 2s 259us/sample - loss: 0.3305 - accuracy: 0.8649 - val_loss: 0.3282 - val_accuracy: 0.8663\n",
            "Epoch 112/300\n",
            "7000/7000 [==============================] - 2s 298us/sample - loss: 0.3302 - accuracy: 0.8643 - val_loss: 0.3284 - val_accuracy: 0.8660\n",
            "Epoch 113/300\n",
            "7000/7000 [==============================] - 2s 256us/sample - loss: 0.3301 - accuracy: 0.8653 - val_loss: 0.3290 - val_accuracy: 0.8664\n",
            "Epoch 114/300\n",
            "7000/7000 [==============================] - 2s 252us/sample - loss: 0.3301 - accuracy: 0.8644 - val_loss: 0.3286 - val_accuracy: 0.8651\n",
            "Epoch 115/300\n",
            "7000/7000 [==============================] - 1s 185us/sample - loss: 0.3305 - accuracy: 0.8641 - val_loss: 0.3279 - val_accuracy: 0.8667\n",
            "Epoch 116/300\n",
            "7000/7000 [==============================] - 2s 240us/sample - loss: 0.3300 - accuracy: 0.8643 - val_loss: 0.3281 - val_accuracy: 0.8663\n",
            "Epoch 117/300\n",
            "7000/7000 [==============================] - 2s 326us/sample - loss: 0.3300 - accuracy: 0.8649 - val_loss: 0.3280 - val_accuracy: 0.8663\n",
            "Epoch 118/300\n",
            "7000/7000 [==============================] - 2s 230us/sample - loss: 0.3303 - accuracy: 0.8667 - val_loss: 0.3279 - val_accuracy: 0.8657\n",
            "Epoch 119/300\n",
            "7000/7000 [==============================] - 2s 286us/sample - loss: 0.3303 - accuracy: 0.8637 - val_loss: 0.3278 - val_accuracy: 0.8664\n",
            "Epoch 120/300\n",
            "7000/7000 [==============================] - 1s 168us/sample - loss: 0.3297 - accuracy: 0.8657 - val_loss: 0.3282 - val_accuracy: 0.8649\n",
            "Epoch 121/300\n",
            "7000/7000 [==============================] - 1s 177us/sample - loss: 0.3302 - accuracy: 0.8654 - val_loss: 0.3281 - val_accuracy: 0.8647\n",
            "Epoch 122/300\n",
            "7000/7000 [==============================] - 1s 175us/sample - loss: 0.3300 - accuracy: 0.8647 - val_loss: 0.3276 - val_accuracy: 0.8651\n",
            "Epoch 123/300\n",
            "7000/7000 [==============================] - 1s 168us/sample - loss: 0.3300 - accuracy: 0.8653 - val_loss: 0.3277 - val_accuracy: 0.8664\n",
            "Epoch 124/300\n",
            "7000/7000 [==============================] - 2s 307us/sample - loss: 0.3297 - accuracy: 0.8657 - val_loss: 0.3278 - val_accuracy: 0.8669\n",
            "Epoch 125/300\n",
            "7000/7000 [==============================] - 1s 154us/sample - loss: 0.3298 - accuracy: 0.8659 - val_loss: 0.3281 - val_accuracy: 0.8641\n",
            "Epoch 126/300\n",
            "7000/7000 [==============================] - 1s 153us/sample - loss: 0.3295 - accuracy: 0.8651 - val_loss: 0.3278 - val_accuracy: 0.8664\n",
            "Epoch 127/300\n",
            "7000/7000 [==============================] - 1s 149us/sample - loss: 0.3300 - accuracy: 0.8641 - val_loss: 0.3278 - val_accuracy: 0.8661\n",
            "Epoch 00127: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZSZqUUxzD3b",
        "colab_type": "code",
        "colab": {},
        "outputId": "84515749-0a1d-4bf8-c69f-619041822219"
      },
      "source": [
        "Opt_mymodel.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 6)                 72        \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 6)                 42        \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 1)                 7         \n",
            "=================================================================\n",
            "Total params: 121\n",
            "Trainable params: 121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODkBtnv6zD3f",
        "colab_type": "text"
      },
      "source": [
        "### 8. Predict the results using 0.5 as a threshold (Optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L9raLPb2zD3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_model_pred = Opt_model.predict(X_test)\n",
        "y_pred = (y_model_pred > 0.5) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad9YKaMMzD3l",
        "colab_type": "text"
      },
      "source": [
        "### 9. Print the Accuracy score and confusion matrix (5 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EulZGKCqzD3n",
        "colab_type": "code",
        "colab": {},
        "outputId": "7013eca2-890d-47bb-c364-281b18d0a91a"
      },
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"ANN Model Confussion Matrix : \\n {0}\\n\".format(cm))\n",
        "\n",
        "TN, FP,FN, TP = cm.ravel()\n",
        "Result=pd.DataFrame(index=[\"TrueNegatives\",\"FalsePositives\",\"FalseNegatives\",\"TruePositives\",\"Accuracy\", \"Recall\", \"Precision\", \"F1_Score\"])\n",
        "\n",
        "ANN_ModelResult=[TN,FP,FN,TP,accuracy_score(y_test, y_pred), \n",
        "                   recall_score(y_test, y_pred), \n",
        "                   precision_score(y_test, y_pred),\n",
        "                   f1_score(y_test, y_pred)]\n",
        "\n",
        "Result[\"ANN_Model_Result\"]=ANN_ModelResult\n",
        "\n",
        "print(\"ANN Model Result : \\n\\n {0}\\n\".format(Result))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ANN Model Confussion Matrix : \n",
            " [[2289  106]\n",
            " [ 306  299]]\n",
            "\n",
            "ANN Model Result : \n",
            "\n",
            "                 ANN_Model_Result\n",
            "TrueNegatives        2289.000000\n",
            "FalsePositives        106.000000\n",
            "FalseNegatives        306.000000\n",
            "TruePositives         299.000000\n",
            "Accuracy                0.862667\n",
            "Recall                  0.494215\n",
            "Precision               0.738272\n",
            "F1_Score                0.592079\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}